# -*- coding: utf-8 -*-
"""Web Scraping Ripley.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fsfh2ZG19uU7_sHy41fZh3rlAiTyRY7a

**Disclaimer:** The content of this notebook is for informational use only.

# Web Scraping

### Introducción
Este **notebook** tiene la finalidad de ser una plantilla simple de como obtener datos con Python. Se obtendra datos mediante Web Scraping, el uso de expresiones regulares y visualización.

## Web Scraping Using Requests and Beautiful Soup (bs4)

Podemos encontrar un elemento en la página inspeccionando la página (haga clic con el botón derecho y presione el elemento de inspección). Luego utilizamos una serie de selectores de HTML para encontrar las etiquetas adecuadas que contengan el contenido que nos interesa. El siguiente bloque de código encuentra el texto principal de todo el artículo. Luego, subdividiremos el texto en la tabla correspondiente y lo guardaremos como un objeto de texto.
"""

# requests para obtener html del sitio web
import requests

from bs4 import BeautifulSoup

# inicializar variables
lista_url = []
lista_product_details_name = []
lista_precio_normal = []
lista_precio_internet = []
lista_precio_ripley = []

URL = 'https://simple.ripley.com.pe/computo/laptops/todas-las-laptops'

# Hacer la solicitud a una URL
req = requests.get(URL)
print(req.status_code)
i = 0
bandera = True
while bandera == True:
#while i < 2:
  
  # Crear un SOUP a partir del contenido del requests
  c = req.content
  soup = BeautifulSoup(c)
  
  # Encuentra el elemento en la página web
  catalog_container = soup.find('div', attrs = {'class': 'catalog-container'})
  
  # Validar si la pagina cuenta con contenido
  if catalog_container is None or len(catalog_container) == 0:
    print("I have nothing to print")
    bandera = False
  else:
    print(catalog_container)
    #for href in catalog_container.find_all('a', href=True):
    for product_item in catalog_container.find_all('a', href=True):
        #print(product_item)
        
        ### FALTA IMAGEN DEL PRODUCTO
        #images-preview-item is-active

        ### URL DE LOS PRODUCTOS ###
        lista_url.append('https://simple.ripley.com.pe'+product_item['href'])

        ### PRODUCTO NOMBRE DETALLE ###
        lista_product_details_name.append(product_item.find('div',attrs = {'class':'catalog-product-details__name'}).text.replace("\"",""))

        ### PRODUCTO PRECIO NORMAL ###
        precio_normal = product_item.find('li',attrs = {'class':'catalog-prices__list-price catalog-prices__lowest'})
        if precio_normal is None or len(precio_normal) == 0:
          lista_precio_normal.append(-1)
          #print("I have nothing to print")
        else:
          lista_precio_normal.append(precio_normal.text.replace("S/ ","").replace(",",""))
          #print(precio_normal.text)

        ### PRODUCTO PRECIO INTERNET ###
        precio_internet = product_item.find('li',attrs = {'class':'catalog-prices__offer-price'})
        if precio_internet is None or len(precio_internet) == 0:
          lista_precio_internet.append(-1)
          #print("I have nothing to print")
        else:
          lista_precio_internet.append(precio_internet.text.replace("S/ ","").replace(",",""))
          #print(precio_normal.text)

        ### PRODUCTO PRECIO INTERNET ###
        precio_ripley = product_item.find('li',attrs = {'class':'catalog-prices__card-price'})
        if precio_ripley is None or len(precio_ripley) == 0:
          lista_precio_ripley.append(-1)
          #print("I have nothing to print")
        else:
          lista_precio_ripley.append(precio_ripley.text.replace("S/ ","").replace(",",""))
          #print(precio_normal.text)

    i += 1
    req = requests.get(URL+'?page='+str(i))
    print(req.status_code)

import pandas as pd

# Put information into a dataframe
df = pd.DataFrame({'url': lista_url, 
                   'product_details_name': lista_product_details_name,
                   'precio_normal' : lista_precio_normal,
                   'lista_precio_internet' : lista_precio_internet,
                   'lista_precio_ripley' : lista_precio_ripley
                  })

df





